<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM-as-Judge Performance Dashboard</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #f8fafc;
            min-height: 100vh;
            color: #1e293b;
            line-height: 1.6;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .header {
            text-align: center;
            margin-bottom: 40px;
            padding: 40px 20px;
            background: #061440; /* Main title: deep navy */
            border-radius: 16px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            border: 1px solid #e2e8f0;
        }
        
        .header h1 {
            font-size: 2.25rem;
            margin-bottom: 8px;
            color: #f8fafc;
            font-weight: 700;
        }
        
        .header p {
            font-size: 1rem;
            color: #cbd5e1;
            font-weight: 400;
        }
        
        .section-header {
            display: flex;
            align-items: center;
            gap: 12px;
            font-size: 1.25rem;
            font-weight: 700;
            color: #f8fafc;
            margin: 32px 0 12px;
            background: #0f172a;
            padding: 12px 16px;
            border-radius: 8px;
        }
        /* Distinct shades per section */
        #judge-performance.section-header { background: #401F0D; /* Judge Performance */ }
        #prompt-battery.section-header { background: #59540A; /* Prompt Battery Explorer */ }
        
        .section-header::before {
            content: '';
            width: 6px;
            height: 24px;
            background: #3b82f6;
            border-radius: 3px;
        }
        
        .section-description {
            font-size: 0.95rem;
            color: #475569;
            margin: 4px 0 16px;
        }
        
        .controls {
            background: white;
            padding: 24px;
            border-radius: 12px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            border: 1px solid #e2e8f0;
            margin-bottom: 32px;
            display: flex;
            gap: 24px;
            flex-wrap: wrap;
            align-items: center;
        }
        
        .control-group {
            display: flex;
            flex-direction: column;
            gap: 5px;
        }
        
        .control-group label {
            font-weight: 500;
            color: #374151;
            font-size: 14px;
        }
        
        select, input {
            padding: 10px 14px;
            border: 1px solid #d1d5db;
            border-radius: 8px;
            font-size: 14px;
            transition: all 0.2s;
            background: white;
        }
        
        select:focus, input:focus {
            outline: none;
            border-color: #3b82f6;
            box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);
        }
        
        .dashboard-grid {
            display: grid;
            grid-template-columns: 1fr; /* stack cards in separate rows */
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .card {
            background: white;
            border-radius: 12px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            border: 1px solid #e2e8f0;
            overflow: hidden;
        }
        
        .card-header {
            background: #401F0D; /* Match Judge Performance section */
            color: #f8fafc;
            padding: 20px 24px;
            font-weight: 600;
            font-size: 1.1rem;
            border-bottom: 1px solid #2b160a;
        }
        
        .card-content {
            padding: 20px;
        }
        
        .prompt-battery {
            margin-bottom: 30px;
        }
        
        .battery-header {
            background: #59540A; /* Match Prompt Battery section */
            color: white;
            padding: 20px 24px;
            border-radius: 12px 12px 0 0;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .battery-title {
            font-size: 1.3rem;
            font-weight: 600;
        }
        
        .battery-stats {
            display: flex;
            gap: 15px;
            font-size: 0.9rem;
        }
        
        .stat-item {
            background: rgba(255,255,255,0.15);
            padding: 6px 12px;
            border-radius: 20px;
            font-size: 0.875rem;
            font-weight: 500;
        }
        
        .scores-table {
            width: 100%;
            background: white;
            border-radius: 0 0 12px 12px;
            overflow: hidden;
        }
        
        .table-container {
            padding: 24px;
        }
        
        .scores-table table {
            width: 100%;
            border-collapse: collapse;
            font-size: 14px;
        }
        
        .scores-table th {
            background: #401F0D; /* Default: Judge Performance tables */
            padding: 16px 12px;
            text-align: left;
            font-weight: 600;
            color: #f8fafc;
            border-bottom: 1px solid #2b160a;
            font-size: 13px;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }
        /* Override table header shade within Prompt Battery section */
        #promptBatteries .scores-table th {
            background: #59540A;
            border-bottom: 1px solid #443f08;
            color: #f8fafc;
        }
        
        .scores-table td {
            padding: 16px 12px;
            border-bottom: 1px solid #f3f4f6;
            vertical-align: middle;
        }
        
        .scores-table tr:hover {
            background: #f9fafb;
        }
        
        .model-name {
            font-weight: 600;
            color: #1f2937;
            min-width: 200px;
        }
        
        .score-cell {
            min-width: 120px;
        }
        
        .score-bar {
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .bar-container {
            flex: 1;
            height: 8px;
            background: #e5e7eb;
            border-radius: 4px;
            overflow: hidden;
        }
        
        .bar-fill {
            height: 100%;
            border-radius: 4px;
            transition: width 0.3s ease;
        }
        
        .score-value {
            font-weight: 600;
            color: #374151;
            font-size: 13px;
            min-width: 40px;
            text-align: right;
        }
        
        .bar-endorse { background: #10b981; }
        .bar-harm { background: #ef4444; }
        .bar-challenge { background: #f59e0b; }
        .bar-flattery { background: #8b5cf6; }
        .bar-accuracy { background: #3b82f6; }
        
        .prompt-list {
            display: flex;
            flex-direction: column;
            gap: 8px;
        }
        
        .prompt-item {
            border: 1px solid #e5e7eb;
            border-radius: 8px;
            background: white;
            transition: all 0.2s;
            overflow: hidden;
        }
        
        .prompt-item:hover {
            border-color: #3b82f6;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .prompt-header {
            padding: 16px 20px;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 12px;
            user-select: none;
        }
        
        .prompt-header:hover {
            background: #f9fafb;
        }
        
        .prompt-id {
            font-weight: 600;
            color: #3b82f6;
            font-size: 14px;
            min-width: 40px;
        }
        
        .prompt-preview {
            flex: 1;
            font-size: 0.95rem;
            color: #374151;
            line-height: 1.4;
            margin-right: 12px;
        }
        
        .prompt-indicators {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 1.1rem;
        }
        
        .expand-icon {
            color: #9ca3af;
            font-size: 0.875rem;
            transition: transform 0.2s;
            min-width: 16px;
        }
        
        .prompt-item.expanded .expand-icon {
            transform: rotate(90deg);
        }
        
        .prompt-details {
            display: none;
            padding: 0 20px 20px 20px;
            border-top: 1px solid #f3f4f6;
            background: #fafbfc;
        }
        
        .prompt-item.expanded .prompt-details {
            display: block;
        }
        
        .prompt-full-text {
            font-size: 0.95rem;
            color: #374151;
            line-height: 1.5;
            margin-bottom: 16px;
            padding: 12px;
            background: white;
            border-radius: 6px;
            border-left: 4px solid #3b82f6;
        }
        
        .prompt-metadata {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));
            gap: 12px;
            margin-bottom: 16px;
        }
        
        .metadata-item {
            display: flex;
            flex-direction: column;
            gap: 4px;
        }
        
        .metadata-label {
            font-size: 0.75rem;
            color: #6b7280;
            font-weight: 500;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }
        
        .metadata-value {
            font-size: 0.875rem;
            color: #374151;
            font-weight: 500;
        }
        
        .judge-scores {
            margin-top: 16px;
        }
        
        .judge-scores-title {
            font-size: 0.875rem;
            font-weight: 600;
            color: #374151;
            margin-bottom: 8px;
        }
        
        .judge-scores-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(100px, 1fr));
            gap: 8px;
        }
        
        .judge-score-item {
            background: white;
            padding: 8px;
            border-radius: 6px;
            border: 1px solid #e5e7eb;
            text-align: center;
        }
        
        .judge-score-label {
            font-size: 0.7rem;
            color: #6b7280;
            margin-bottom: 2px;
        }
        
        .judge-score-value {
            font-size: 0.8rem;
            font-weight: 600;
            color: #374151;
        }
        
        .loading {
            text-align: center;
            padding: 40px;
            color: #666;
        }
        
        .error {
            background: #f8d7da;
            color: #721c24;
            padding: 15px;
            border-radius: 8px;
            margin: 20px 0;
        }
        
        @media (max-width: 768px) {
            .dashboard-grid {
                grid-template-columns: 1fr;
            }
            
            .controls {
                flex-direction: column;
                align-items: stretch;
            }
            
            .prompt-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üß† LLM-as-Judge Performance Dashboard</h1>
            <p>Evaluating judge models' scoring behavior across prompt batteries</p>
        </div>
        
        <!-- Judge Model Performance Section -->
        <div class="section-header" id="judge-performance" role="heading" aria-level="2">Judge Model Performance</div>
        <p class="section-description" id="judge-performance-desc">
            Overview of how each LLM acting as a judge performs on the evaluation set. The table shows overall
            accuracy and accuracy within key categories (challenge, agreement, evasion). Bars represent percentage
            accuracy; higher is better.
        </p>
        <div class="controls" id="performanceControls" aria-label="Performance Controls">
            <div class="control-group">
                <label for="modelSelect">Judge Model:</label>
                <select id="modelSelect">
                    <option value="">All Judges</option>
                </select>
            </div>
        </div>
        
        <div class="dashboard-grid">
            <div class="card">
                <div class="card-header">üìä Judge Model Performance Overview</div>
                <div class="card-content">
                    <p class="section-description">
                        Each row is a judge model. Overall shows total accuracy across the dataset; category columns
                        show accuracy restricted to that behavior class.
                    </p>
                    <div id="modelScoresTable"></div>
                </div>
            </div>

            <div class="card">
                <div class="card-header">üí≤ Cost and Usage (per model)</div>
                <div class="card-content">
                    <p class="section-description">
                        Aggregated token usage and estimated costs computed from the evaluation run summaries.
                        Use this to understand efficiency across judge models.
                    </p>
                    <div id="costUsageTable"></div>
                </div>
            </div>
        </div>
        
        <!-- Prompt Battery Explorer Section -->
        <div class="section-header" id="prompt-battery" role="heading" aria-level="2">Prompt Battery Explorer</div>
        <p class="section-description" id="prompt-battery-desc">
            Explore prompts designed to test sycophantic behavior in LLMs. Each prompt is crafted to elicit agreement or validation from models, 
            revealing their tendency to be overly agreeable rather than providing balanced, critical responses. Click any prompt to expand 
            and view judge model scores when available.
        </p>
        <div class="section-description" style="background: #f8fafc; padding: 16px; border-radius: 8px; border-left: 4px solid #3b82f6; margin-bottom: 16px;">
            <strong>Visual Indicators Guide:</strong><br>
            üî¥ <strong>Harmful Content</strong> - Tests model's willingness to validate dangerous or problematic viewpoints<br>
            üü¢ <strong>Safe Content</strong> - Tests sycophantic behavior on benign topics like preferences or opinions<br>
            üëπ <strong>Devil's Advocate</strong> - Explicitly instructs model to challenge the user's position first<br>
            üìà <strong>High Strength</strong> - Strong, confident assertions that maximally test sycophantic resistance<br>
            üìä <strong>Medium Strength</strong> - Moderate assertions creating balanced testing conditions<br>
            üìâ <strong>Low Strength</strong> - Tentative phrasing that may naturally invite agreement<br>
            üëç <strong>Positive Stance</strong> - User supports the topic, testing if model reinforces this position<br>
            üëé <strong>Negative Stance</strong> - User opposes the topic, testing if model validates contrary views
        </div>
        <div class="controls" id="promptControls" aria-label="Prompt Filters">
            <div class="control-group">
                <label for="topicFilter">Topic:</label>
                <select id="topicFilter">
                    <option value="">All Topics</option>
                </select>
            </div>
            <div class="control-group">
                <label for="stanceFilter">Stance:</label>
                <select id="stanceFilter">
                    <option value="">All Stances</option>
                    <option value="1">Positive</option>
                    <option value="-1">Negative</option>
                </select>
            </div>
            <div class="control-group">
                <label for="strengthFilter">Strength:</label>
                <select id="strengthFilter">
                    <option value="">All Strengths</option>
                    <option value="0.2">Low (0.2)</option>
                    <option value="0.5">Medium (0.5)</option>
                    <option value="0.8">High (0.8)</option>
                </select>
            </div>
            <div class="control-group">
                <label for="searchInput">Search:</label>
                <input type="text" id="searchInput" placeholder="Search prompts...">
            </div>
        </div>
        <div id="promptBatteries">
            <div class="loading">Loading prompt batteries...</div>
        </div>
    </div>

    <script>
        class LLMJudgeDashboard {
            constructor() {
                this.promptBattery = [];
                this.evaluationResults = {};
                this.summaryData = {};
                this.filteredData = [];
                
                this.init();
            }
            
            async init() {
                try {
                    await this.loadData();
                    this.setupEventListeners();
                    this.populateFilters();
                    this.renderDashboard();
                } catch (error) {
                    this.showError('Failed to load data: ' + error.message);
                }
            }
            
            async loadData() {
                // Load prompt battery
                const batteryResponse = await fetch('/api/prompt_battery');
                this.promptBattery = await batteryResponse.json();
                
                // Load evaluation results
                await this.loadEvaluationResults();
            }
            
            async loadEvaluationResults() {
                try {
                    // Load summaries first
                    const response = await fetch('/api/evaluation_results');
                    const summaries = await response.json();
                    this.evaluationResults = summaries || {};

                    const modelNames = Object.keys(this.evaluationResults);
                    if (modelNames.length === 0) return; // nothing to enrich

                    // Fetch detailed results per model in parallel and merge
                    await Promise.all(
                        modelNames.map(async (model) => {
                            try {
                                const res = await fetch(`/api/evaluation_results/${encodeURIComponent(model)}`);
                                if (!res.ok) return;
                                const full = await res.json();
                                if (!this.evaluationResults[model]) this.evaluationResults[model] = {};
                                this.evaluationResults[model].detailed = full.detailed || [];
                                // Prefer backend summary if provided
                                if (full.summary) {
                                    this.evaluationResults[model].summary = full.summary;
                                }
                            } catch (e) {
                                console.warn('Failed loading detailed for model', model, e);
                            }
                        })
                    );
                } catch (error) {
                    console.error('Failed to load evaluation results:', error);
                    this.evaluationResults = {};
                }
            }
            
            setupEventListeners() {
                document.getElementById('modelSelect').addEventListener('change', () => this.applyFilters());
                document.getElementById('topicFilter').addEventListener('change', () => this.applyFilters());
                document.getElementById('stanceFilter').addEventListener('change', () => this.applyFilters());
                document.getElementById('strengthFilter').addEventListener('change', () => this.applyFilters());
                document.getElementById('searchInput').addEventListener('input', () => this.applyFilters());
            }
            
            populateFilters() {
                // Populate topic filter
                const topics = [...new Set(this.promptBattery.map(p => p.topic))];
                const topicSelect = document.getElementById('topicFilter');
                topics.forEach(topic => {
                    const option = document.createElement('option');
                    option.value = topic;
                    option.textContent = topic.charAt(0).toUpperCase() + topic.slice(1);
                    topicSelect.appendChild(option);
                });
                
                // Populate model filter
                const models = Object.keys(this.evaluationResults);
                const modelSelect = document.getElementById('modelSelect');
                models.forEach(model => {
                    const option = document.createElement('option');
                    option.value = model;
                    option.textContent = model;
                    modelSelect.appendChild(option);
                });
            }
            
            applyFilters() {
                const modelFilter = document.getElementById('modelSelect').value;
                const topicFilter = document.getElementById('topicFilter').value;
                const stanceFilter = document.getElementById('stanceFilter').value;
                const strengthFilter = document.getElementById('strengthFilter').value;
                const searchTerm = document.getElementById('searchInput').value.toLowerCase();
                
                this.filteredData = this.promptBattery.filter(prompt => {
                    if (topicFilter && prompt.topic !== topicFilter) return false;
                    if (stanceFilter && prompt.stance.toString() !== stanceFilter) return false;
                    if (strengthFilter && prompt.strength.toString() !== strengthFilter) return false;
                    if (searchTerm && !prompt.text.toLowerCase().includes(searchTerm)) return false;
                    return true;
                });
                
                this.renderPromptBatteries();
            }
            
            renderDashboard() {
                this.renderModelScoresTable();
                this.renderCostUsageTable();
                this.applyFilters();
            }
            
            renderModelScoresTable() {
                const container = document.getElementById('modelScoresTable');
                
                if (Object.keys(this.evaluationResults).length === 0) {
                    container.innerHTML = '<p class="text-gray-500">No evaluation data available</p>';
                    return;
                }
                
                let tableHTML = `
                    <table class="scores-table">
                        <thead>
                            <tr>
                                <th>Model</th>
                                <th>Overall Accuracy</th>
                                <th>Challenge</th>
                                <th>Agreement</th>
                                <th>Evasion</th>
                            </tr>
                        </thead>
                        <tbody>
                `;
                
                Object.entries(this.evaluationResults).forEach(([modelName, data]) => {
                    const summary = data.summary || {};
                    const metrics = summary.metrics || {};
                    const categoryMetrics = metrics.category_metrics || {};
                    
                    const overallAccuracy = (metrics.overall_accuracy || 0) * 100;
                    const challengeAccuracy = (categoryMetrics.CHALLENGE?.accuracy || 0) * 100;
                    const agreementAccuracy = (categoryMetrics.AGREEMENT?.accuracy || 0) * 100;
                    const evasionAccuracy = (categoryMetrics.EVASION?.accuracy || 0) * 100;
                    
                    tableHTML += `
                        <tr>
                            <td class="model-name">${modelName}</td>
                            <td class="score-cell">
                                <div class="score-bar">
                                    <div class="bar-container">
                                        <div class="bar-fill bar-accuracy" style="width: ${overallAccuracy}%"></div>
                                    </div>
                                    <span class="score-value">${overallAccuracy.toFixed(1)}%</span>
                                </div>
                            </td>
                            <td class="score-cell">
                                <div class="score-bar">
                                    <div class="bar-container">
                                        <div class="bar-fill bar-challenge" style="width: ${challengeAccuracy}%"></div>
                                    </div>
                                    <span class="score-value">${challengeAccuracy.toFixed(1)}%</span>
                                </div>
                            </td>
                            <td class="score-cell">
                                <div class="score-bar">
                                    <div class="bar-container">
                                        <div class="bar-fill bar-endorse" style="width: ${agreementAccuracy}%"></div>
                                    </div>
                                    <span class="score-value">${agreementAccuracy.toFixed(1)}%</span>
                                </div>
                            </td>
                            <td class="score-cell">
                                <div class="score-bar">
                                    <div class="bar-container">
                                        <div class="bar-fill bar-harm" style="width: ${evasionAccuracy}%"></div>
                                    </div>
                                    <span class="score-value">${evasionAccuracy.toFixed(1)}%</span>
                                </div>
                            </td>
                        </tr>
                    `;
                });
                
                tableHTML += `
                        </tbody>
                    </table>
                `;
                
                container.innerHTML = tableHTML;
            }

            renderCostUsageTable() {
                const container = document.getElementById('costUsageTable');
                if (!container) return;

                if (Object.keys(this.evaluationResults).length === 0) {
                    container.innerHTML = '<p class="text-gray-500">No cost/usage data available</p>';
                    return;
                }

                let tableHTML = `
                    <table class="scores-table">
                        <thead>
                            <tr>
                                <th>Model</th>
                                <th>Total Cost (USD)</th>
                                <th>Total Tokens</th>
                                <th>Prompt Tokens</th>
                                <th>Completion Tokens</th>
                                <th>Avg Tokens/Resp</th>
                                <th>Avg Cost/Resp</th>
                                <th>Cost per 1k Tokens</th>
                            </tr>
                        </thead>
                        <tbody>
                `;

                Object.entries(this.evaluationResults).forEach(([model, data]) => {
                    const cs = (data.summary && data.summary.cost_summary) || {};
                    const totalCost = cs.total_cost_usd ?? 0;
                    const totalTokens = cs.total_tokens ?? 0;
                    const promptTokens = cs.total_prompt_tokens ?? 0;
                    const completionTokens = cs.total_completion_tokens ?? 0;
                    const avgTokens = cs.avg_tokens_per_response ?? 0;
                    const avgCost = cs.avg_cost_per_response ?? 0;
                    const costPerK = cs.cost_per_1k_tokens ?? 0;

                    tableHTML += `
                        <tr>
                            <td class="model-name">${model}</td>
                            <td>${totalCost.toFixed ? totalCost.toFixed(4) : totalCost}</td>
                            <td>${Math.round(totalTokens).toLocaleString()}</td>
                            <td>${Math.round(promptTokens).toLocaleString()}</td>
                            <td>${Math.round(completionTokens).toLocaleString()}</td>
                            <td>${avgTokens.toFixed ? avgTokens.toFixed(1) : avgTokens}</td>
                            <td>${avgCost.toFixed ? avgCost.toFixed(6) : avgCost}</td>
                            <td>${costPerK.toFixed ? costPerK.toFixed(6) : costPerK}</td>
                        </tr>
                    `;
                });

                tableHTML += `
                        </tbody>
                    </table>
                `;

                container.innerHTML = tableHTML;
            }
            
            renderCategoryChart() {
                const categoryCtx = document.getElementById('categoryChart').getContext('2d');
                
                // Aggregate category metrics across all models
                const categoryData = { CHALLENGE: [], AGREEMENT: [], EVASION: [] };
                
                Object.values(this.evaluationResults).forEach(result => {
                    if (result.summary && result.summary.metrics && result.summary.metrics.category_metrics) {
                        const categories = result.summary.metrics.category_metrics;
                        Object.keys(categoryData).forEach(cat => {
                            if (categories[cat]) {
                                categoryData[cat].push(categories[cat].accuracy * 100);
                            }
                        });
                    }
                });
                
                // Calculate averages
                const avgAccuracies = Object.keys(categoryData).map(cat => {
                    const accuracies = categoryData[cat];
                    return accuracies.length > 0 ? 
                        accuracies.reduce((a, b) => a + b, 0) / accuracies.length : 0;
                });
                
                new Chart(categoryCtx, {
                    type: 'bar',
                    data: {
                        labels: ['Challenge', 'Agreement', 'Evasion'],
                        datasets: [{
                            label: 'Accuracy (%)',
                            data: avgAccuracies,
                            backgroundColor: ['#f59e0b', '#10b981', '#ef4444'],
                            borderRadius: 8,
                            borderWidth: 0
                        }]
                    },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        scales: {
                            y: {
                                beginAtZero: true,
                                max: 100,
                                grid: {
                                    color: '#f3f4f6'
                                },
                                ticks: {
                                    color: '#6b7280'
                                }
                            },
                            x: {
                                grid: {
                                    display: false
                                },
                                ticks: {
                                    color: '#6b7280'
                                }
                            }
                        },
                        plugins: {
                            legend: {
                                display: false
                            }
                        }
                    }
                });
            }
            
            renderPromptBatteries() {
                const container = document.getElementById('promptBatteries');
                
                if (this.filteredData.length === 0) {
                    container.innerHTML = '<div class="loading">No prompts match the current filters.</div>';
                    return;
                }
                
                // Group by topic
                const groupedByTopic = this.filteredData.reduce((acc, prompt) => {
                    if (!acc[prompt.topic]) acc[prompt.topic] = [];
                    acc[prompt.topic].push(prompt);
                    return acc;
                }, {});
                
                container.innerHTML = '';
                
                Object.entries(groupedByTopic).forEach(([topic, prompts]) => {
                    const batteryDiv = document.createElement('div');
                    batteryDiv.className = 'prompt-battery';
                    
                    const harmfulCount = prompts.filter(p => p.is_harmful).length;
                    const devilCount = prompts.filter(p => p.ask_devil).length;
                    
                    batteryDiv.innerHTML = `
                        <div class="battery-header">
                            <div class="battery-title">${topic.charAt(0).toUpperCase() + topic.slice(1)} Battery</div>
                            <div class="battery-stats">
                                <div class="stat-item">${prompts.length} prompts</div>
                                <div class="stat-item">${harmfulCount} harmful</div>
                                <div class="stat-item">${devilCount} devil's advocate</div>
                            </div>
                        </div>
                        <div class="prompt-list">
                            ${this.renderPromptList(prompts)}
                        </div>
                    `;
                    
                    container.appendChild(batteryDiv);
                });
                
                // Add click handlers for expand/collapse
                this.setupPromptExpansion();
            }
            
            renderPromptList(prompts) {
                return prompts.map(prompt => {
                    const preview = prompt.text.length > 80 ? prompt.text.substring(0, 80) + '...' : prompt.text;
                    const indicators = this.getPromptIndicators(prompt);
                    
                    return `
                        <div class="prompt-item" data-prompt-id="${prompt.prompt_id}">
                            <div class="prompt-header">
                                <div class="prompt-id">${prompt.prompt_id}</div>
                                <div class="prompt-preview">${preview}</div>
                                <div class="prompt-indicators">${indicators}</div>
                                <div class="expand-icon">‚ñ∂</div>
                            </div>
                            <div class="prompt-details">
                                <div class="prompt-full-text">${prompt.text}</div>
                                <div class="prompt-metadata">
                                    <div class="metadata-item">
                                        <div class="metadata-label">Topic</div>
                                        <div class="metadata-value">${prompt.topic}</div>
                                    </div>
                                    <div class="metadata-item">
                                        <div class="metadata-label">Persona</div>
                                        <div class="metadata-value">${prompt.persona}</div>
                                    </div>
                                    <div class="metadata-item">
                                        <div class="metadata-label">Stance</div>
                                        <div class="metadata-value">${prompt.stance === 1 ? 'Positive' : 'Negative'}</div>
                                    </div>
                                    <div class="metadata-item">
                                        <div class="metadata-label">Strength</div>
                                        <div class="metadata-value">${this.getStrengthText(prompt.strength)}</div>
                                    </div>
                                </div>
                                ${this.renderJudgeScores(prompt.prompt_id)}
                            </div>
                        </div>
                    `;
                }).join('');
            }
            
            getPromptIndicators(prompt) {
                const indicators = [];
                
                if (prompt.is_harmful) {
                    indicators.push('<span title="üî¥ Harmful Content: Tests if the model validates or endorses potentially harmful viewpoints, revealing sycophantic agreement with dangerous ideas">üî¥</span>');
                } else {
                    indicators.push('<span title="üü¢ Safe Content: Tests sycophantic behavior on non-harmful topics like preferences, opinions, or benign decisions">üü¢</span>');
                }
                
                if (prompt.ask_devil) {
                    indicators.push('<span title="üëπ Devil\'s Advocate: Explicitly asks the model to challenge the user\'s position first, testing if it can resist sycophantic agreement when instructed to be critical">üëπ</span>');
                }
                
                // Strength indicator
                const strengthIcon = prompt.strength === 0.8 ? 'üìà' : prompt.strength === 0.5 ? 'üìä' : 'üìâ';
                let strengthTitle;
                if (prompt.strength === 0.8) {
                    strengthTitle = 'üìà High Strength: Strong, confident assertion that maximally tests sycophantic tendencies - harder for models to resist agreeing';
                } else if (prompt.strength === 0.5) {
                    strengthTitle = 'üìä Medium Strength: Moderate assertion with some uncertainty, creating balanced sycophancy testing conditions';
                } else {
                    strengthTitle = 'üìâ Low Strength: Tentative, uncertain phrasing that may naturally invite agreement, testing baseline sycophantic responses';
                }
                indicators.push(`<span title="${strengthTitle}">${strengthIcon}</span>`);
                
                // Stance indicator
                const stanceIcon = prompt.stance === 1 ? 'üëç' : 'üëé';
                let stanceTitle;
                if (prompt.stance === 1) {
                    stanceTitle = 'üëç Positive Stance: User expresses support/agreement with the topic - tests if model will sycophantically reinforce this position';
                } else {
                    stanceTitle = 'üëé Negative Stance: User expresses opposition/disagreement with the topic - tests if model will sycophantically validate this contrary view';
                }
                indicators.push(`<span title="${stanceTitle}">${stanceIcon}</span>`);
                
                return indicators.join(' ');
            }
            
            getStrengthText(strength) {
                return strength === 0.8 ? 'High' : strength === 0.5 ? 'Medium' : 'Low';
            }
            
            renderJudgeScores(promptId) {
                const selectedModel = document.getElementById('modelSelect').value;
                if (!selectedModel || !this.evaluationResults[selectedModel] || !this.evaluationResults[selectedModel].detailed) {
                    return '<div class="judge-scores"><div class="judge-scores-title">Judge Scores</div><p style="color: #6b7280; font-size: 0.875rem;">Select a judge model to view scores</p></div>';
                }
                
                const detailed = this.evaluationResults[selectedModel].detailed;
                const promptScores = detailed.find(item => item.prompt_id === promptId);
                
                if (!promptScores) {
                    return '<div class="judge-scores"><div class="judge-scores-title">Judge Scores</div><p style="color: #6b7280; font-size: 0.875rem;">No scores available for this prompt</p></div>';
                }
                
                return `
                    <div class="judge-scores">
                        <div class="judge-scores-title">Judge Scores (${selectedModel})</div>
                        <div class="judge-scores-grid">
                            ${promptScores.endorse_stance !== undefined ? `
                                <div class="judge-score-item">
                                    <div class="judge-score-label">Endorse</div>
                                    <div class="judge-score-value">${(promptScores.endorse_stance * 100).toFixed(0)}%</div>
                                </div>
                            ` : ''}
                            ${promptScores.harm_validation !== undefined ? `
                                <div class="judge-score-item">
                                    <div class="judge-score-label">Harm</div>
                                    <div class="judge-score-value">${(promptScores.harm_validation * 100).toFixed(0)}%</div>
                                </div>
                            ` : ''}
                            ${promptScores.challenge_user !== undefined ? `
                                <div class="judge-score-item">
                                    <div class="judge-score-label">Challenge</div>
                                    <div class="judge-score-value">${(promptScores.challenge_user * 100).toFixed(0)}%</div>
                                </div>
                            ` : ''}
                            ${promptScores.flattery !== undefined ? `
                                <div class="judge-score-item">
                                    <div class="judge-score-label">Flattery</div>
                                    <div class="judge-score-value">${(promptScores.flattery * 100).toFixed(0)}%</div>
                                </div>
                            ` : ''}
                        </div>
                    </div>
                `;
            }
            
            setupPromptExpansion() {
                document.querySelectorAll('.prompt-header').forEach(header => {
                    header.addEventListener('click', (e) => {
                        const promptItem = header.closest('.prompt-item');
                        promptItem.classList.toggle('expanded');
                        
                        // Re-render judge scores if expanded and model selected
                        if (promptItem.classList.contains('expanded')) {
                            const promptId = promptItem.dataset.promptId;
                            const judgeScoresContainer = promptItem.querySelector('.judge-scores');
                            if (judgeScoresContainer) {
                                judgeScoresContainer.outerHTML = this.renderJudgeScores(promptId);
                            }
                        }
                    });
                });
            }
            
            showError(message) {
                const container = document.getElementById('promptBatteries');
                container.innerHTML = `<div class="error">${message}</div>`;
            }
        }
        
        // Initialize dashboard when page loads
        document.addEventListener('DOMContentLoaded', () => {
            new LLMJudgeDashboard();
        });
    </script>
</body>
</html>
